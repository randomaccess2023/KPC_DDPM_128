{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a2f983",
   "metadata": {},
   "source": [
    "# <center>Calculate FID distance using samples generated with `Linear` scheduler</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebac148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import pathlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2975dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_WEIGHTS_URL = 'https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1aa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    '''Pre-trained InceptionV3 network returning feature maps'''\n",
    "    \n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "    BLOCK_INDEX_BY_DIM = {64: 0, 192: 1, 768: 2, 2048: 3}\n",
    "    \n",
    "    def __init__(self, output_blocks=(DEFAULT_BLOCK_INDEX,), resize_input=True, normalize_input=True, requires_grad=False,\n",
    "                 use_fid_inception=True):\n",
    "        super(InceptionV3, self).__init__()\n",
    "        \n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "        \n",
    "        assert self.last_needed_block <= 3, 'Last possible output block index is 3'\n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        if use_fid_inception:\n",
    "            inception = fid_inception_v3()\n",
    "        else:\n",
    "            inception = _inception_v3(weights='DEFAULT')\n",
    "            \n",
    "        block0 = [inception.Conv2d_1a_3x3, inception.Conv2d_2a_3x3, inception.Conv2d_2b_3x3,\n",
    "                  nn.MaxPool2d(kernel_size=3, stride=2)]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "        \n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [inception.Conv2d_3b_1x1, inception.Conv2d_4a_3x3, nn.MaxPool2d(kernel_size=3, stride=2)]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "        \n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [inception.Mixed_5b, inception.Mixed_5c, inception.Mixed_5d, inception.Mixed_6a, inception.Mixed_6b,\n",
    "                      inception.Mixed_6c, inception.Mixed_6d, inception.Mixed_6e]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "            \n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [inception.Mixed_7a, inception.Mixed_7b, inception.Mixed_7c, nn.AdaptiveAvgPool2d(output_size=(1, 1))]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "            \n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "            \n",
    "    def forward(self, input_):\n",
    "        output = []\n",
    "        x = input_\n",
    "        \n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1\n",
    "            \n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                output.append(x)\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8ff155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inception_v3(*args, **kwargs):\n",
    "    '''Wraps `torchvision.models.inception_v3`'''\n",
    "    \n",
    "    try:\n",
    "        version = tuple(map(int, torchvision.__version__.split('.')[:2]))\n",
    "    except ValueError:\n",
    "        version = (0,)\n",
    "        \n",
    "    if version >= (0, 6):\n",
    "        kwargs['init_weights'] = False\n",
    "        \n",
    "    if version < (0, 13) and 'weights' in kwargs:\n",
    "        if kwargs['weights'] == 'DEFAULT':\n",
    "            kwargs['pretrained'] = True\n",
    "        elif kwargs['weights'] is None:\n",
    "            kwargs['pretrained'] = False\n",
    "        else:\n",
    "            raise ValueError('weights=={} not supported in torchvision {}'.format(kwargs['weights'], torchvision.__version__))\n",
    "        del kwargs['weights']\n",
    "        \n",
    "    return torchvision.models.inception_v3(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523a1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_inception_v3():\n",
    "    \n",
    "    inception = _inception_v3(num_classes=1008, aux_logits=False, weights=None)\n",
    "    \n",
    "    inception.Mixed_5b = FIDInceptionA(192, pool_features=32)\n",
    "    inception.Mixed_5c = FIDInceptionA(256, pool_features=64)\n",
    "    inception.Mixed_5d = FIDInceptionA(288, pool_features=64)\n",
    "    inception.Mixed_6b = FIDInceptionC(768, channels_7x7=128)\n",
    "    inception.Mixed_6c = FIDInceptionC(768, channels_7x7=160)\n",
    "    inception.Mixed_6d = FIDInceptionC(768, channels_7x7=160)\n",
    "    inception.Mixed_6e = FIDInceptionC(768, channels_7x7=192)\n",
    "    inception.Mixed_7b = FIDInceptionE_1(1280)\n",
    "    inception.Mixed_7c = FIDInceptionE_2(2048)\n",
    "    \n",
    "    state_dict = load_state_dict_from_url(FID_WEIGHTS_URL, progress=True)\n",
    "    inception.load_state_dict(state_dict)\n",
    "    \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68dd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIDInceptionA(models.inception.InceptionA):\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(FIDInceptionA, self).__init__(in_channels, pool_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1, count_include_pad=False)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f0e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIDInceptionC(models.inception.InceptionC):\n",
    "    def __init__(self, in_channels, channels_7x7):\n",
    "        super(FIDInceptionC, self).__init__(in_channels, channels_7x7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "        \n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1, count_include_pad=False)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9a15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIDInceptionE_1(models.inception.InceptionE):\n",
    "    def __init__(self, in_channels):\n",
    "        super(FIDInceptionE_1, self).__init__(in_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [self.branch3x3_2a(branch3x3), self.branch3x3_2b(branch3x3)]\n",
    "        branch3x3 = torch.cat(branch3x3, dim=1)\n",
    "        \n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [self.branch3x3dbl_3a(branch3x3dbl), self.branch3x3dbl_3b(branch3x3dbl)]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, dim=1)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1, count_include_pad=False)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c414b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIDInceptionE_2(models.inception.InceptionE):\n",
    "    def __init__(self, in_channels):\n",
    "        super(FIDInceptionE_2, self).__init__(in_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [self.branch3x3_2a(branch3x3), self.branch3x3_2b(branch3x3)]\n",
    "        branch3x3 = torch.cat(branch3x3, dim=1)\n",
    "        \n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [self.branch3x3dbl_3a(branch3x3dbl), self.branch3x3dbl_3b(branch3x3dbl)]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, dim=1)\n",
    "        \n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2a2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTENSIONS = {'jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df4450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, files, transform=None):\n",
    "        \n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        path = self.files[i]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "097823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(files, model, batch_size, dims, device='cpu'):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if batch_size > len(files):\n",
    "        batch_size = len(files)\n",
    "        \n",
    "    dataset = ImagePathDataset(files, transform=transforms.ToTensor())\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    pred_arr = np.empty((len(files), dims))\n",
    "    start_idx = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            pred = model(batch)[0]\n",
    "            \n",
    "        if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "            pred = F.adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "        \n",
    "        pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
    "        pred_arr[start_idx:start_idx+pred.shape[0]] = pred\n",
    "        start_idx = start_idx + pred.shape[0]\n",
    "        \n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22637133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, mu2, sigma1, sigma2, eps=1e-6):\n",
    "    \n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    \n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    \n",
    "    assert mu1.shape == mu2.shape, 'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, 'Training and test covariances have different dimensions'\n",
    "    \n",
    "    diff = mu1 - mu2\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces sigular product; adding %s to diagonal cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "        \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "        \n",
    "    tr_covmean = np.trace(covmean)\n",
    "    \n",
    "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50baba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(files, model, batch_size, dims, device='cpu'):\n",
    "    \n",
    "    act = get_activations(files, model, batch_size, dims, device)\n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b953a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_of_path(path, model, batch_size, dims, device='cpu'):\n",
    "    \n",
    "    if path.endswith('.npz'):\n",
    "        with np.load(path) as f:\n",
    "            mu, sigma = f['mu'][:], f['sigma'][:]\n",
    "            \n",
    "    else:\n",
    "        path = pathlib.Path(path)\n",
    "        files = sorted([file for ext in IMAGE_EXTENSIONS for file in path.glob('*.{}'.format(ext))])\n",
    "        mu, sigma = calculate_activation_statistics(files, model, batch_size, dims, device)\n",
    "        \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41af0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid_given_paths(path1, path2, batch_size, dims, device='cpu'):\n",
    "    \n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "    model = InceptionV3([block_idx]).to(device)\n",
    "    \n",
    "    mu1, sigma1 = compute_statistics_of_path(path1, model, batch_size, dims, device)\n",
    "    mu2, sigma2 = compute_statistics_of_path(path2, model, batch_size, dims, device)\n",
    "    \n",
    "    fid_value = calculate_frechet_distance(mu1, mu2, sigma1, sigma2)\n",
    "    return print('FID distance:', round(fid_value, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8472971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in src_path: 11000\n",
      "Total images in gen_path: 11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 220/220 [00:30<00:00,  7.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 220/220 [00:30<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID distance: 36.833\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 50\n",
    "dims = 2048\n",
    "\n",
    "src_path = '../SRC'\n",
    "gen_path = '../GEN_Linear'\n",
    "\n",
    "print('Total images in src_path:', len(next(os.walk(src_path))[2]))\n",
    "print('Total images in gen_path:', len(next(os.walk(gen_path))[2]))\n",
    "\n",
    "calculate_fid_given_paths(path1=src_path, path2=gen_path, batch_size=batch_size, dims=dims, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
